<!-- Generated by SpecStory -->

# Design a production-ready proxy service (2025-06-26 09:58:08)

_**User**_

Act as a senior software architect and Python expert.

Goal  
Design a robust, production-ready proxy service that:  
• Implements the OpenAI REST API spec (chat/completions, embeddings, etc.) so it is a drop-in replacement for official endpoints.  
• Transparently forwards each incoming request to one or more configurable LLM provider back-ends (e.g., OpenAI, Anthropic, Azure OpenAI, local models) and returns the selected response.  
• Logs every request, response, timing, and metadata in a research-ready format for later analysis.  
• Adheres to modern Python best practices (type hints, linting, async IO, dependency injection, modular design, testing, CI/CD, security).

Deliverables  
Please produce a detailed project plan that contains:

1. High-level architecture  
   • Main components and how they interact (HTTP layer, routing/orchestration, provider adapters, logging layer, persistence, config, auth, observability).  
   • Recommended protocols, libraries, and patterns (e.g., FastAPI, pydantic, httpx/asyncio, structured logging, OpenTelemetry).  

2. API surface  
   • Endpoint list matching the OpenAI spec, including required/optional fields and example payloads.  
   • Any additional internal/admin endpoints (health, metrics).  

3. Provider abstraction layer  
   • Strategy for pluggable adapters. 
   • Configuration of provider credentials via env vars/secrets.  

4. Logging & data storage  
   • Schema for storing requests/responses, including token counts and latency.  
   • Recommendations for database/warehouse choices and GDPR/PII handling.  

5. Security & compliance  
   • Authentication/authorization options (API keys).   

6. Observability & reliability  
   • Metrics, tracing, structured logs.  
   • Graceful error handling, retries, timeouts, circuit breakers.  

7. Testing strategy  
   • Unit, integration, contract, and load tests; mocking external APIs.  

8. Deployment & operations  
   • Containerization (Docker)
   • Rollback/versioning strategy, config management, secret handling.  

9. Project structure & coding standards  
   • Recommended folder layout, naming conventions, pre-commit hooks, lint/format tools.  
   • Use of type annotations, mypy, Ruff/Flake8, Black, isort.  

10. Timeline & milestones  
    • Phased implementation roadmap with estimated effort per phase.

Present the plan in clear sections with bullet points, code snippets where useful, and concise explanations.

Write your plan in ai-docs/project-plan.md file.

---

_**Assistant**_



---

```diff
- 
+ # AI Proxy – Project Architecture Plan
+ 
+ ## 1. High-level Architecture
+ 
+ ```
+ +-------------------+       +------------------+       +-------------------+
+ |    Client Apps    |  -->  |  HTTP/API Layer  |  -->  |  Router / Orchestrator |
+ +-------------------+       +------------------+       +-------------------+
+                                                    |        |         |
+                                                    v        v         v
+                                           +-------------+ +-----------+ +-----------+
+                                           | OpenAI      | | Anthropic | | Local LLM |
+                                           +-------------+ +-----------+ +-----------+
+                                                    |
+                                                    v
+                                         +---------------------+
+                                         |  Logging & Storage  |
+                                         +---------------------+
+ ```
+ 
+ • **HTTP/API Layer** – FastAPI (async, pydantic validation).  
+ • **Router / Orchestrator** – Decides provider(s) per request, applies retries, circuit breakers.  
+ • **Provider Adapters** – Pluggable, async classes wrapping each LLM backend via httpx.  
+ • **Config & Secrets** – `pydantic.Settings` + env vars / Vault.  
+ • **Auth** – API-key header (hashed in DB or Redis).  
+ • **Observability** – OpenTelemetry traces, Prometheus metrics, JSON logs.  
+ • **Persistence** – PostgreSQL for structured logs; optional warehouse export.
+ 
+ Patterns: Clean/Hexagonal architecture, Dependency-Injection (`python-dependency-injector`), Factory for adapters, Repository for DB.
+ 
+ ## 2. API Surface (OpenAI-compatible)
+ 
+ | Method | Path | Description |
+ |--------|------|-------------|
+ | POST | /v1/chat/completions | Chat endpoint |
+ | POST | /v1/completions | Legacy completions |
+ | POST | /v1/embeddings | Embedding generation |
+ | GET  | /v1/models | List supported models |
+ | ...  | ... | (follow official spec) |
+ 
+ Example `POST /v1/chat/completions` request:
+ ```json
+ {
+   "model": "gpt-3.5-turbo",
+   "messages": [{"role": "user", "content": "Hello"}],
+   "temperature": 0.7,
+   "stream": false
+ }
+ ```
+ 
+ Additional internal endpoints:
+ • `GET /healthz` – liveness & readiness.  
+ • `GET /metrics` – Prometheus scrape.  
+ • `GET /admin/providers` – runtime status (auth-protected).
+ 
+ ## 3. Provider Abstraction Layer
+ 
+ ```python
+ class BaseProvider(ABC):
+     name: str
+ 
+     @abstractmethod
+     async def chat(self, payload: ChatPayload) -> ChatResponse: ...
+ ```
+ 
+ Adapters: `OpenAIAdapter`, `AnthropicAdapter`, `AzureOpenAIAdapter`, `LocalLLMAdapter`.  
+ Loaded via entry-points or config:
+ ```yaml
+ providers:
+   - type: openai
+     api_key: ${OPENAI_API_KEY}
+   - type: anthropic
+     api_key: ${ANTHROPIC_KEY}
+ ```
+ 
+ ## 4. Logging & Data Storage
+ 
+ Schema (PostgreSQL / Parquet):
+ ```
+ request_id  UUID PK
+ user_id     TEXT
+ endpoint    TEXT
+ model       TEXT
+ prompt_tokens INT
+ completion_tokens INT
+ latency_ms  INT
+ provider    TEXT
+ status_code SMALLINT
+ cost_usd    NUMERIC(10,5)
+ created_at  TIMESTAMPTZ
+ request_sha BYTEA
+ response_sha BYTEA
+ ```
+ • Store only hashes of payloads by default; raw text optionally encrypted (AES-256).  
+ • GDPR: configurable retention, delete/forget API, PII minimization.
+ 
+ ## 5. Security & Compliance
+ 
+ • HTTPS only, TLS 1.2+.  
+ • HMAC-signed API keys or JWT; RBAC scopes per key.  
+ • Rate limiting & quota via Redis `lua` scripts.  
+ • Secrets managed by HashiCorp Vault / AWS Secrets Manager.  
+ • Dependabot + SCA scanning, OWASP headers, audit logging.
+ 
+ ## 6. Observability & Reliability
+ 
+ • **Metrics** – requests/sec, p99 latency, error %, token usage, provider cost.  
+ • **Tracing** – OpenTelemetry → Jaeger / Tempo.  
+ • **Logging** – structlog JSON + log rotation.  
+ • **Resilience** – Tenacity retries, async-timeout, `aiobreaker` circuit breaker, bulkhead concurrency limits.
+ 
+ ## 7. Testing Strategy
+ 
+ • Unit tests (pytest, pytest-asyncio, 90% cov).  
+ • Integration tests with testcontainers-postgres and mock provider servers.  
+ • Contract tests vs OpenAI schema (Schemathesis).  
+ • Load testing with k6 / Locust CI job.
+ 
+ ## 8. Deployment & Operations
+ 
+ • **Container** – Multi-stage Dockerfile → 50 MB image, non-root user.  
+ • **Runtime** – Uvicorn workers under Gunicorn or `uvicorn --workers=N`.  
+ • **Orchestrator** – Kubernetes/Helm; rolling update, HPA.  
+ • **Config** – 12-Factor via env; Helm values per env.  
+ • **Release flow** – Git tag → CI → Docker → Helm chart → Canary → Promote.  
+ • Rollback via Helm `history`.
+ 
+ ## 9. Project Structure & Standards
+ 
+ ```
+ ai-proxy/
+ ├─ ai_proxy/
+ │  ├─ api/            # FastAPI routers
+ │  ├─ adapters/       # provider implementations
+ │  ├─ core/           # business logic (router, services)
+ │  ├─ schemas/        # pydantic models
+ │  ├─ db/             # repos & migrations (Alembic)
+ │  ├─ config.py
+ │  └─ logging.py
+ ├─ tests/
+ ├─ ai-docs/
+ ├─ pyproject.toml     # Poetry, Black, Ruff, isort, mypy
+ └─ Dockerfile
+ ```
+ 
+ Coding rules: Black formatter, isort, Ruff lint, mypy strict, pre-commit, Conventional Commits.
+ 
+ ## 10. Timeline & Milestones (15 dev-days)
+ 
+ | Phase | Task | Est. |
+ |-------|------|------|
+ | 0 | Bootstrap repo, CI, linters | 1d |
+ | 1 | API skeleton & OpenAI spec routes | 2d |
+ | 2 | Provider interface + OpenAI adapter | 2d |
+ | 3 | Routing/orchestration logic | 2d |
+ | 4 | Structured logging & Postgres integration | 2d |
+ | 5 | Auth, rate-limiting, security hardening | 1d |
+ | 6 | Observability (metrics, tracing) | 1d |
+ | 7 | Additional adapters (Anthropic, Azure, Local) | 3d |
+ | 8 | Testing & load test scripts | 1d |
+ | 9 | Docker/Helm deploy pipeline, docs | 1d |
+ | **Total** |  | **15d** |
+ 
+ ---
+ End of plan. 
```

---



---

