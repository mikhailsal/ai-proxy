<!-- Generated by SpecStory -->

# Создание прокси для API LLM-модели (2025-06-26 09:53:26)

_**User**_

Привет. Я собираюсь создать свой собственный прокси. Для API LLM-модели искусственного интеллекта. Я хочу сделать прокси совместимым протоколом API OpenAI  и переадресовывать запросы на другие API e возвращать результаты. То есть это что-то вроде прокси роутер. При этом очень важно логировать все запросы, которые будут ко мне приходить, потому что на их основе будет происходить исследование по запросам и ответам искусственного интеллекта. Твоя задача написать качественный промт для модели искусственного интеллекта чтобы она разработала план для проекта на python используя лучшие практики программирования. Обрати внимание, сейчас тебе не нужно ничего делать. Не нужно писать план разработки. Задача написать качественный промт на английском языке. И вернуть его мне.

---

_**Assistant**_



---

Below is the English-language prompt you can feed to an AI model to obtain a high-quality development plan.

---

Act as a senior software architect and Python expert.

Goal  
Design a robust, production-ready proxy service that:  
• Implements the OpenAI REST API spec (chat/completions, embeddings, etc.) so it is a drop-in replacement for official endpoints.  
• Transparently forwards each incoming request to one or more configurable LLM provider back-ends (e.g., OpenAI, Anthropic, Azure OpenAI, local models) and returns the selected response.  
• Logs every request, response, timing, and metadata in a research-ready format for later analysis.  
• Adheres to modern Python best practices (type hints, linting, async IO, dependency injection, modular design, testing, CI/CD, security).

Deliverables  
Please produce a detailed project plan that contains:

1. High-level architecture  
   • Main components and how they interact (HTTP layer, routing/orchestration, provider adapters, logging layer, persistence, config, auth, observability).  
   • Recommended protocols, libraries, and patterns (e.g., FastAPI, pydantic, httpx/asyncio, structured logging, OpenTelemetry).  

2. API surface  
   • Endpoint list matching the OpenAI spec, including required/optional fields and example payloads.  
   • Any additional internal/admin endpoints (health, metrics).  

3. Provider abstraction layer  
   • Strategy for pluggable adapters and load-balancing/fallback rules.  
   • Configuration of provider credentials via env vars/secrets.  

4. Logging & data storage  
   • Schema for storing requests/responses, including token counts and latency.  
   • Recommendations for database/warehouse choices and GDPR/PII handling.  

5. Security & compliance  
   • Authentication/authorization options (API keys, OAuth, mTLS).  
   • Rate limiting, request validation, input sanitization.  

6. Observability & reliability  
   • Metrics, tracing, structured logs.  
   • Graceful error handling, retries, timeouts, circuit breakers.  

7. Testing strategy  
   • Unit, integration, contract, and load tests; mocking external APIs.  

8. Deployment & operations  
   • Containerization (Docker), orchestration (Kubernetes), and CI/CD pipeline diagram.  
   • Rollback/versioning strategy, config management, secret handling.  

9. Project structure & coding standards  
   • Recommended folder layout, naming conventions, pre-commit hooks, lint/format tools.  
   • Use of type annotations, mypy, Ruff/Flake8, Black, isort.  

10. Timeline & milestones  
    • Phased implementation roadmap with estimated effort per phase.

Present the plan in clear sections with bullet points, code snippets where useful, and concise explanations.

---

