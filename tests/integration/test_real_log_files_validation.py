"""
Integration tests for validating real log files format.

This test suite validates that actual log files generated by the system
follow the correct format and can be parsed by the log ingestion system.
This is an integration test as it validates the interaction between
logging components, file system, and log parsing functionality.
"""

import json
import re
from pathlib import Path
from typing import List, Dict, Any

import pytest


class TestRealLogFilesValidation:
    """Test suite for validating real log files."""

    @pytest.fixture
    def log_dir(self) -> Path:
        """Get the logs directory."""
        return Path("/app/logs")

    def _extract_json_blocks(self, log_content: str) -> List[str]:
        """Extract JSON blocks from log content using the same logic as the parser."""
        json_blocks = []
        lines = log_content.split("\n")

        buffer = None
        depth = 0

        for line in lines:
            if buffer is None:
                brace_idx = line.find("{")
                if brace_idx == -1:
                    continue
                buffer = [line[brace_idx:]]
                depth = buffer[-1].count("{") - buffer[-1].count("}")
                if depth == 0:
                    json_text = "".join(buffer).strip()
                    if json_text:  # Only add non-empty blocks
                        json_blocks.append(json_text)
                    buffer = None
                continue

            # We are inside a JSON block
            buffer.append(line)
            depth += line.count("{") - line.count("}")
            if depth <= 0:
                json_text = "".join(buffer).strip()
                if json_text:  # Only add non-empty blocks
                    json_blocks.append(json_text)
                buffer = None

        return json_blocks

    def _validate_log_entry(self, json_text: str) -> Dict[str, Any]:
        """Validate a single log entry and return parsed JSON."""
        # Skip empty or whitespace-only entries
        if not json_text.strip():
            return {}

        try:
            entry = json.loads(json_text)
        except json.JSONDecodeError as e:
            # Skip malformed entries with debug info
            print(f"Skipping malformed JSON entry: {e}")
            print(f"Content preview: {json_text[:100]}...")
            return {}

        if not isinstance(entry, dict):
            print(f"Skipping non-dict entry: {type(entry)}")
            return {}

        return entry

    def _validate_timestamp_format(self, timestamp: str) -> None:
        """Validate timestamp format."""
        # Should be ISO format with Z suffix
        iso_pattern = r"^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d+Z$"
        if not re.match(iso_pattern, timestamp):
            pytest.fail(f"Invalid timestamp format: {timestamp}")

    def test_v1_chat_completions_log_format(self, log_dir: Path):
        """Test that v1_chat_completions.log has correct format."""
        log_file = log_dir / "v1_chat_completions.log"

        if not log_file.exists():
            pytest.skip("v1_chat_completions.log not found")

        content = log_file.read_text(encoding="utf-8")
        json_blocks = self._extract_json_blocks(content)

        if not json_blocks:
            pytest.skip("No JSON blocks found in v1_chat_completions.log")

        # Test a sample of entries (not all to keep test fast)
        sample_size = min(10, len(json_blocks))
        sample_blocks = json_blocks[-sample_size:]  # Test recent entries

        for i, json_text in enumerate(sample_blocks):
            entry = self._validate_log_entry(json_text)

            # Skip empty entries
            if not entry:
                continue

            # Only validate entries that look like API requests
            if not all(field in entry for field in ["request", "response", "endpoint"]):
                continue  # Skip test entries or other log types

            # Required fields for chat completions
            required_fields = ["timestamp", "endpoint", "request", "response"]
            for field in required_fields:
                if field not in entry:
                    pytest.fail(f"Missing required field '{field}' in entry {i}")

            # Validate timestamp
            self._validate_timestamp_format(entry["timestamp"])

            # Validate endpoint
            if entry["endpoint"] != "/v1/chat/completions":
                pytest.fail(f"Unexpected endpoint: {entry['endpoint']}")

            # Validate request structure
            request = entry["request"]
            if not isinstance(request, dict):
                pytest.fail(f"Request is not a dict in entry {i}")

            # Validate response structure
            response = entry["response"]
            if not isinstance(response, dict):
                pytest.fail(f"Response is not a dict in entry {i}")

            # Optional fields validation
            if "status_code" in entry:
                if not isinstance(entry["status_code"], int):
                    pytest.fail(f"status_code is not an int in entry {i}")

            if "latency_ms" in entry:
                if not isinstance(entry["latency_ms"], (int, float)):
                    pytest.fail(f"latency_ms is not numeric in entry {i}")

    def test_v1_models_log_format(self, log_dir: Path):
        """Test that v1_models.log has correct format."""
        log_file = log_dir / "v1_models.log"

        if not log_file.exists():
            pytest.skip("v1_models.log not found")

        content = log_file.read_text(encoding="utf-8")
        json_blocks = self._extract_json_blocks(content)

        if not json_blocks:
            pytest.skip("No JSON blocks found in v1_models.log")

        for i, json_text in enumerate(json_blocks):
            entry = self._validate_log_entry(json_text)

            # Required fields
            if "timestamp" in entry:
                self._validate_timestamp_format(entry["timestamp"])

            if "endpoint" in entry:
                if entry["endpoint"] != "/v1/models":
                    pytest.fail(f"Unexpected endpoint: {entry['endpoint']}")

    def test_model_specific_logs_format(self, log_dir: Path):
        """Test that model-specific logs have correct format."""
        models_dir = log_dir / "models"

        if not models_dir.exists():
            pytest.skip("models directory not found")

        model_log_files = list(models_dir.glob("*.log"))

        if not model_log_files:
            pytest.skip("No model log files found")

        # Test a few model log files
        for log_file in model_log_files[:3]:  # Test first 3 to keep test fast
            content = log_file.read_text(encoding="utf-8")
            json_blocks = self._extract_json_blocks(content)

            if not json_blocks:
                continue  # Skip empty files

            # Test all entries to find at least one with model fields
            has_model_entry = False
            for json_text in json_blocks:
                entry = self._validate_log_entry(json_text)

                # Skip empty entries
                if not entry:
                    continue

                # Model logs should have timestamp
                if "timestamp" in entry:
                    self._validate_timestamp_format(entry["timestamp"])

                # Check if this entry has model-related fields
                model_fields = ["original_model", "mapped_model", "model_name"]
                if any(field in entry for field in model_fields):
                    has_model_entry = True
                    break

            if not has_model_entry:
                pytest.fail(f"No model fields found in any entry of {log_file.name}")

    def test_app_log_format(self, log_dir: Path):
        """Test that app.log has correct format."""
        log_file = log_dir / "app.log"

        if not log_file.exists():
            pytest.skip("app.log not found")

        content = log_file.read_text(encoding="utf-8")

        # App log might have different format, just check it's readable
        if not content.strip():
            pytest.skip("app.log is empty")

        # Try to find JSON blocks
        json_blocks = self._extract_json_blocks(content)

        for json_text in json_blocks[:5]:  # Test first 5 entries
            entry = self._validate_log_entry(json_text)

            if "timestamp" in entry:
                self._validate_timestamp_format(entry["timestamp"])

    def test_no_ansi_codes_in_log_files(self, log_dir: Path):
        """Test that log files don't contain ANSI color codes."""
        ansi_escape = re.compile(r"\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])")

        log_files = [
            log_dir / "v1_chat_completions.log",
            log_dir / "v1_models.log",
            log_dir / "app.log",
        ]

        for log_file in log_files:
            if not log_file.exists():
                continue

            content = log_file.read_text(encoding="utf-8")

            # Check for ANSI codes
            ansi_matches = ansi_escape.findall(content)
            if ansi_matches:
                pytest.fail(f"Found ANSI codes in {log_file.name}: {ansi_matches[:5]}")

    def test_log_entries_have_consistent_structure(self, log_dir: Path):
        """Test that log entries have consistent structure within each file type."""
        log_file = log_dir / "v1_chat_completions.log"

        if not log_file.exists():
            pytest.skip("v1_chat_completions.log not found")

        content = log_file.read_text(encoding="utf-8")
        json_blocks = self._extract_json_blocks(content)

        if len(json_blocks) < 2:
            pytest.skip("Not enough entries to test consistency")

        # Filter for actual API request/response entries (not test entries)
        api_entries = []
        for json_text in json_blocks:
            entry = self._validate_log_entry(json_text)
            # Look for entries that have both request and response (actual API calls)
            if "request" in entry and "response" in entry and "endpoint" in entry:
                api_entries.append(entry)

        if len(api_entries) < 2:
            pytest.skip("Not enough API entries to test consistency")

        # Get field sets from API entries
        field_sets = [set(entry.keys()) for entry in api_entries[:5]]

        # All API entries should have similar core fields
        common_fields = set.intersection(*field_sets) if field_sets else set()

        # Should have at least timestamp, endpoint, request, response
        expected_core_fields = {"timestamp", "endpoint", "request", "response"}
        missing_core_fields = expected_core_fields - common_fields

        if missing_core_fields:
            pytest.fail(f"Missing core fields in API entries: {missing_core_fields}")

    def test_unicode_handling_in_logs(self, log_dir: Path):
        """Test that logs handle Unicode characters correctly."""
        log_file = log_dir / "v1_chat_completions.log"

        if not log_file.exists():
            pytest.skip("v1_chat_completions.log not found")

        try:
            # This should not raise UnicodeDecodeError
            content = log_file.read_text(encoding="utf-8")

            # If we have content with Unicode, it should be valid
            if any(ord(char) > 127 for char in content):
                # File contains Unicode characters, verify they're handled correctly
                json_blocks = self._extract_json_blocks(content)

                for json_text in json_blocks[:3]:  # Test first 3
                    self._validate_log_entry(json_text)
                    # If we get here, Unicode was handled correctly

        except UnicodeDecodeError:
            pytest.fail("Log file contains invalid UTF-8 encoding")

    def test_log_file_line_endings(self, log_dir: Path):
        """Test that log files use consistent line endings."""
        log_files = [log_dir / "v1_chat_completions.log", log_dir / "v1_models.log"]

        for log_file in log_files:
            if not log_file.exists():
                continue

            with open(log_file, "rb") as f:
                content = f.read()

            # Check for mixed line endings (which can cause parsing issues)
            has_crlf = b"\r\n" in content
            has_lf = b"\n" in content and b"\r\n" not in content
            has_cr = b"\r" in content and b"\r\n" not in content

            line_ending_types = sum([has_crlf, has_lf, has_cr])

            if line_ending_types > 1:
                pytest.fail(f"Mixed line endings detected in {log_file.name}")
